################ ëª°ë“œ í…œí”„ ì „ì²˜ë¦¬

import pandas as pd
import plotly.express as px

train = pd.read_csv('./data/train.csv')

train['molten_temp'].value_counts()

# registration_timeì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
train['registration_time'] = pd.to_datetime(train['registration_time'], errors='coerce')

# ì‹œê³„ì—´ ê·¸ë˜í”„ (molten_temp ë³€í™”)
fig = px.line(
    train,
    x="registration_time",
    y="molten_temp",
    title="Molten Temperature over Time",
    labels={"registration_time": "ë“±ë¡ ì¼ì‹œ", "molten_temp": "ìš©íƒ• ì˜¨ë„ (â„ƒ)"},
    template="plotly_dark"
)

# ì¤Œì¸/ì•„ì›ƒ ë° hover ê¸°ëŠ¥ í™œì„±í™”
fig.update_xaxes(rangeslider_visible=True)
fig.show()
# molten_tempë³„ ë¹ˆë„ ê³„ì‚° í›„ ì‘ì€ ê°’ë¶€í„° ì •ë ¬
molten_counts = train['molten_temp'].value_counts().sort_index()

# ì‘ì€ ê°’ë¶€í„° 50ê°œë§Œ í™•ì¸
molten_counts.head(50)


# ë³´ê³  ì‹¶ì€ ê°’ ë¦¬ìŠ¤íŠ¸
target_vals = [0.0, 7.0, 70.0, 71.0, 72.0, 73.0]

# ê° ê°’ë³„ passorfail ë¹„ìœ¨ ê³„ì‚°
ratio_df = (
    train[train['molten_temp'].isin(target_vals)]
    .groupby('molten_temp')['passorfail']
    .value_counts(normalize=True)  # ë¹„ìœ¨ ê³„ì‚°
    .unstack(fill_value=0)         # ì—´ë¡œ í¼ì¹˜ê¸°
    .rename(columns={0.0: "ì–‘í’ˆë¹„ìœ¨", 1.0: "ë¶ˆëŸ‰ë¹„ìœ¨"})
)

print(ratio_df)


# 0ë„, 7ë„ ì¡°ê±´
mask = train['molten_temp'].isin([70.0, 71.0,72,73])
idx_list = train[mask].index

# ì „í›„ 3í–‰ì”© í™•ì¸
for i in idx_list:
    print(train.loc[i-3:i+3, ["registration_time", "molten_temp", "passorfail"]])
    print("="*60)


# 7ë„ì¸ í–‰ ì¸ë±ìŠ¤ ì¶”ì¶œ
idx_list = train[train['molten_temp'] == 7.0].index

# ì „í›„ 3í–‰ì”© í™•ì¸
for i in idx_list:
    print(f"ğŸ”¹ molten_temp=7.0 at index {i}")
    print(train.loc[i-3:i+3, ["registration_time", "molten_temp", "passorfail"]])
    print("="*60)



import pandas as pd
import numpy as np
import plotly.express as px

# ----- ë°ì´í„° ë¡œë“œ
train = pd.read_csv("./data/train.csv")

# ----- datetime ë³€í™˜ (ì‹œê³„ì—´ ê·¸ë˜í”„ìš©)
train['registration_time'] = pd.to_datetime(train['registration_time'], errors='coerce')

# ----- Step 1. 100 ì´í•˜ â†’ NaN ë³€í™˜
train['molten_temp_clean'] = train['molten_temp'].where(train['molten_temp'] >= 100, np.nan)

# ----- Step 2. NaNì„ ì•ë’¤ í‰ê· ìœ¼ë¡œ ë³´ì •
def fill_nan_with_neighbors(series):
    vals = series.copy()
    for i in range(len(vals)):
        if pd.isna(vals.iloc[i]):
            prev_idx = i - 1
            next_idx = i + 1

            # ì• íƒìƒ‰
            while prev_idx >= 0 and pd.isna(vals.iloc[prev_idx]):
                prev_idx -= 1
            # ë’¤ íƒìƒ‰
            while next_idx < len(vals) and pd.isna(vals.iloc[next_idx]):
                next_idx += 1

            # ì•ë’¤ ëª¨ë‘ ê°’ì´ ìˆìœ¼ë©´ í‰ê· 
            if prev_idx >= 0 and next_idx < len(vals):
                vals.iloc[i] = np.mean([vals.iloc[prev_idx], vals.iloc[next_idx]])
            elif prev_idx >= 0:  # ì•ë§Œ ìˆìœ¼ë©´ ì•ê°’
                vals.iloc[i] = vals.iloc[prev_idx]
            elif next_idx < len(vals):  # ë’¤ë§Œ ìˆìœ¼ë©´ ë’¤ê°’
                vals.iloc[i] = vals.iloc[next_idx]
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ NaN ìœ ì§€
    return vals

train['molten_temp_filled'] = fill_nan_with_neighbors(train['molten_temp_clean'])

# ----- Plotly ì‹œê°í™” (ë³´ì • ì „ vs ë³´ì • í›„ ë¹„êµ)
fig = px.line(
    train,
    x="registration_time",
    y=["molten_temp", "molten_temp_filled"],
    labels={"value": "Molten Temperature (â„ƒ)", "registration_time": "ë“±ë¡ ì¼ì‹œ"},
    title="Molten Temperature (Before vs After Correction)"
)

fig.update_xaxes(rangeslider_visible=True)
fig.show()
train['molten_temp_filled'].value_counts()

train['molten_temp'] = train['molten_temp_filled']
train['molten_temp'].value_counts()

import pandas as pd
import plotly.express as px

train = pd.read_csv("./data/train.csv")

# datetime ë³€í™˜
train['registration_time'] = pd.to_datetime(train['registration_time'], errors='coerce')

# ì‹œê³„ì—´ Plotly ê·¸ë˜í”„
fig = px.line(
    train,
    x="registration_time",
    y="molten_volume",  # âœ… ì •í™•í•œ ì»¬ëŸ¼ëª… ì‚¬ìš©
    labels={
        "registration_time": "ë“±ë¡ ì¼ì‹œ",
        "molten_volume": "ì„¤ë¹„ ì‘ë™ ì‚¬ì´í´ ì‹œê°„"
    },
    title="Facility Operation CycleTime over Time"
)

fig.update_xaxes(rangeslider_visible=True)
fig.show()

train[train['facility_operation_cycleTime'] >= 300]

train.columns

train.isna().sum()

import numpy as np
import pandas as pd
from itertools import groupby
from operator import itemgetter

# ë°ì´í„° ë¡œë”©
train = pd.read_csv("./data/train.csv")
test = pd.read_csv("./data/test.csv")

def extract_cycles(series, threshold=0.5):
    """ìŠ¤ë¬´ë”©ëœ ì‹œê³„ì—´ì—ì„œ ì „í™˜ì  ê¸°ë°˜ ì‚¬ì´í´ ì¶”ì¶œ (ì„ê³„ì¹˜ ì ìš©)"""
    series = np.asarray(series)
    diff = np.diff(series)

    turns = []
    for i in range(1, len(diff)):
        if np.sign(diff[i]) != np.sign(diff[i-1]) and abs(diff[i]) > threshold:
            turns.append(i)
    turns = np.array(turns)

    cycles = []
    for i in range(len(turns)-1):
        cycles.append(series[turns[i]:turns[i+1]])
    return cycles



def fill_with_cycles(series, window=5, n_cycles=5):
    values = series.values.copy()
    nan_idx = np.where(np.isnan(values))[0]

    # ìŠ¤ë¬´ë”© ì ìš©
    smooth = pd.Series(values).rolling(window=window, center=True, min_periods=1).mean().values

    # ì—°ì† NaN ë¸”ë¡ ì°¾ê¸°
    nan_groups = []
    for k, g in groupby(enumerate(nan_idx), lambda ix: ix[0]-ix[1]):
        block = list(map(itemgetter(1), g))
        nan_groups.append(block)

    for block in nan_groups:
        start, end = block[0], block[-1]
        block_len = len(block)

        prev_vals = smooth[:start][~np.isnan(smooth[:start])]
        next_vals = smooth[end+1:][~np.isnan(smooth[end+1:])]

        prev_cycles = extract_cycles(prev_vals) if len(prev_vals) > 10 else []
        next_cycles = extract_cycles(next_vals) if len(next_vals) > 10 else []

        if len(prev_cycles) >= n_cycles:
            pattern = np.concatenate(prev_cycles[-n_cycles:])
        elif len(next_cycles) >= n_cycles:
            pattern = np.concatenate(next_cycles[:n_cycles])
        elif len(prev_cycles) > 0:
            pattern = np.concatenate(prev_cycles)
        elif len(next_cycles) > 0:
            pattern = np.concatenate(next_cycles)
        else:
            # fallback: ì•ë’¤ ê°’ìœ¼ë¡œ ì„ í˜•ë³´ê°„
            pattern = np.linspace(values[start-1], values[end+1], block_len)

        reps = int(np.ceil(block_len / len(pattern))) + 1
        filled = np.tile(pattern, reps)[:block_len]
        values[start:end+1] = filled

    return pd.Series(values, index=series.index)

# 1) ì´ìƒì¹˜ â†’ NaN ì²˜ë¦¬
mask = train["molten_volume"] > 200
outlier_idx = train.index[mask]
outlier_val = train.loc[mask, "molten_volume"]
train.loc[mask, "molten_volume"] = np.nan

# 2) íŒ¨í„´ ê¸°ë°˜ ë³´ê°„ ì‹¤í–‰
train["molten_volume_interp"] = fill_with_cycles(train["molten_volume"], window=5, n_cycles=5)

# 3) ì›ë³¸ ë³µì› (ì´ìƒì¹˜ ë˜ì‚´ë¦¬ê¸°)
train.loc[outlier_idx, "molten_volume"] = outlier_val

cast_pressure                       1
biscuit_thickness                   1
-
lower_mold_temp1                    1
lower_mold_temp2                    1
lower_mold_temp3                  313
sleeve_temperature                  1
physical_strength                   1
Coolant_temperature                 1



import pandas as pd

train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')

train.columns
train

import pandas as pd

train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')

# ë°©ë²• 1: groupby + size
date_counts = train.groupby('time').size().reset_index(name='count')
print(date_counts)

# ë°©ë²• 2: value_counts (ë” ê°„ë‹¨)
date_counts2 = train['time'].value_counts().sort_index()
print(date_counts2)

train["time"] = pd.to_datetime(train["time"], errors="coerce")  # ë‚ ì§œë¡œ ë³€í™˜
train["day"] = train["time"].dt.date   # ë‚ ì§œë§Œ ì¶”ì¶œ (ì˜ˆ: 2019-01-02)


# í•˜ë£¨ ì´ ìƒì‚°ëŸ‰
daily_total = train.groupby("day")["count"].max().reset_index(name="daily_total")


# í•˜ë£¨-ëª°ë“œì½”ë“œë³„ ìƒì‚°ëŸ‰
daily_mold = train.groupby(["day", "mold_code"])["count"].max().reset_index(name="mold_count")

# í•˜ë£¨ ì´í•©ê³¼ í•©ì¹˜ê¸°
daily_mold = daily_mold.merge(daily_total, on="day")

# ë¹„ìœ¨ ê³„ì‚°
daily_mold["ratio"] = daily_mold["mold_count"] / daily_mold["daily_total"]


import matplotlib.pyplot as plt

pivot_mold = daily_mold.pivot(index="day", columns="mold_code", values="ratio").fillna(0)
pivot_mold.plot(kind="bar", stacked=True, figsize=(14,6))
plt.title("ë‚ ì§œë³„ ëª°ë“œì½”ë“œ ë¹„ìœ¨")
plt.ylabel("ë¹„ìœ¨")
plt.show()

import seaborn as sns

sns.scatterplot(data=daily_mold, x="ratio", y="daily_total", hue="mold_code")
plt.title("ëª°ë“œì½”ë“œ ë¹„ìœ¨ vs í•˜ë£¨ ìƒì‚°ëŸ‰")
plt.show()


import pandas as pd

# ë°ì´í„° ë¡œë“œ
train = pd.read_csv("./data/train.csv")
train["time"] = pd.to_datetime(train["time"], errors="coerce")
train["day"] = train["time"].dt.date

# ---- 1. í•˜ë£¨ ì‹¤ì œ ì‚°ì¶œëŸ‰ (count ê¸°ì¤€) ----
daily_actual = train.groupby("day")["count"].agg(["min", "max"]).reset_index()
daily_actual["daily_actual"] = daily_actual["max"] - daily_actual["min"] + 1

# ---- 2. ëª°ë“œì½”ë“œë³„ í‰ê·  facility cycle time ----
cycle_stats = (
    train.groupby(["day", "mold_code"])["facility_operation_cycleTime"]
    .mean()
    .reset_index(name="avg_facility_cycleTime")
)

# ---- 3. ì´ë¡ ì  ì‚°ì¶œëŸ‰ (24ì‹œê°„ ê¸°ì¤€) ----
WORK_TIME = 24 * 60 * 60  # í•˜ë£¨ 24ì‹œê°„ = 86,400ì´ˆ
cycle_stats["theoretical_output"] = (WORK_TIME / cycle_stats["avg_facility_cycleTime"]).round()

# ---- 4. merge (day ê¸°ì¤€) ----
result = cycle_stats.merge(daily_actual[["day", "daily_actual"]], on="day")

# ---- 5. ì˜¤ì°¨ìœ¨ ê³„ì‚° ----
result["error_rate(%)"] = (
    (result["daily_actual"] - result["theoretical_output"]) 
    / result["theoretical_output"] * 100
).round(2)

# ---- 6. ê²°ê³¼ í™•ì¸ ----
print(result.head(15))
