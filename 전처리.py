

















import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer


# ----------------------
# Custom Transformers
# ----------------------

class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):
    """date, time ‚Üí datetime, hour, shift, global_count, monthly_count ÏÉùÏÑ±"""
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        df = X.copy()

        if "date" in df.columns and "time" in df.columns:
            df["datetime"] = pd.to_datetime(
                df["date"].astype(str) + " " + df["time"].astype(str),
                errors="coerce",
                infer_datetime_format=True
            )

        df["hour"] = df["datetime"].dt.hour
        df["shift"] = df["hour"].apply(lambda h: "Day" if 8 <= h <= 19 else "Night")

        # global_count
        global_counts, accum, prev_count = [], 0, df.loc[0, "count"]
        for current_count in df["count"]:
            if current_count < prev_count:
                accum += prev_count
            global_counts.append(accum + current_count)
            prev_count = current_count
        df["global_count"] = global_counts

        # monthly_count
        df["year_month"] = df["datetime"].dt.to_period("M")
        df["monthly_count"] = df.groupby("year_month").cumcount() + 1

        return df

class FeatureEngineer(BaseEstimator, TransformerMixin):
    """ÌååÏÉùÎ≥ÄÏàò + Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨"""
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        df = X.copy()

        # ÌååÏÉùÎ≥ÄÏàò
        df["speed_ratio"] = df["low_section_speed"] / df["high_section_speed"]
        df["pressure_speed_ratio"] = df["cast_pressure"] / df["high_section_speed"]

        # ÏòàÏô∏ Ï≤òÎ¶¨ (0 ÎÇòÎàóÏÖà ‚Üí -1)
        df.loc[(df["low_section_speed"] == 0) & (df["high_section_speed"] == 0), "speed_ratio"] = -1
        df.loc[(df["low_section_speed"] != 0) & (df["high_section_speed"] == 0), "speed_ratio"] = -1
        df.loc[df["high_section_speed"] == 0, "pressure_speed_ratio"] = -1

        # heating_furnace Í∏∞Î≥∏Í∞í
        if "heating_furnace" in df.columns:
            df["heating_furnace"] = df["heating_furnace"].fillna("C")

        # molten_temp ‚Üí ÏµúÎπàÍ∞í
        if "molten_temp" in df.columns:
            df["molten_temp"] = df["molten_temp"].fillna(df["molten_temp"].mode()[0])

        # molten_volume ‚Üí Î≥¥Í∞Ñ
        if "molten_volume" in df.columns:
            df["molten_volume"] = df["molten_volume"].interpolate(method="linear").ffill().bfill()

        # ‚úÖ ÏµúÏ¢Ö ÏïàÏ†ÑÏû•Ïπò: Î™®Îì† inf/-inf ‚Üí -1
        df = df.replace([np.inf, -np.inf], -1)

        return df




class DropColumns(BaseEstimator, TransformerMixin):
    """Î∂àÌïÑÏöîÌïú Ïª¨Îüº ÏÇ≠Ï†ú"""
    def __init__(self, drop_cols=None):
        self.drop_cols = drop_cols if drop_cols else []

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        df = X.copy()
        return df.drop(columns=[c for c in self.drop_cols if c in df.columns])


# ----------------------
# ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ïÏùò
# ----------------------
def build_pipeline():
    drop_cols = [
        "id", "line", "name", "mold_name",
        "date", "time", "registration_time",
        "year_month", "hour", "datetime", "real_time",
        "working"
    ]

    multi_cols = ["mold_code", "heating_furnace", "EMS_operation_time"]
    binary_cols = ["emergency_stop", "tryshot_signal"]

    cat_encoder = ColumnTransformer(
        transformers=[
            ("multi", OneHotEncoder(handle_unknown="ignore", sparse_output=False), multi_cols),
            ("shift", OneHotEncoder(handle_unknown="ignore", sparse_output=False), ["shift"]),
            ("binary", OneHotEncoder(handle_unknown="ignore", sparse_output=False), binary_cols),
        ],
        remainder="passthrough"
    )

    pipeline = Pipeline(steps=[
        ("datetime", DatetimeFeatureExtractor()),
        ("engineer", FeatureEngineer()),
        ("drop", DropColumns(drop_cols=drop_cols)),
        ("encode", cat_encoder)
    ])
    return pipeline




# ----------------------
# DataFrame Î≥ÄÌôò Ìï®Ïàò
# ----------------------

def pipeline_to_dataframe(pipeline, X, fit=False):
    """ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ ÌõÑ DataFrame Î∞òÌôò"""
    if fit:
        Xt = pipeline.fit_transform(X)
    else:
        Xt = pipeline.transform(X)

    feature_names = []
    enc = pipeline.named_steps["encode"]

    for name, trans, cols in enc.transformers_:
        if name in ["multi", "shift", "binary"]:   # ‚úÖ binary Ï∂îÍ∞Ä
            feature_names.extend(trans.get_feature_names_out(cols))
        elif name == "remainder":
            feature_names.extend(cols)

    return pd.DataFrame(Xt, columns=feature_names, index=X.index)


# ----------------------
# Ïã§Ìñâ
# ----------------------
if __name__ == "__main__":
    train = pd.read_csv("./data/train.csv")
    test = pd.read_csv("./data/test.csv")

    y_train = train["passorfail"]
    X_train = train.drop(columns=["passorfail"])
    X_test = test.copy()

    pipeline = build_pipeline()

    # train Î≥ÄÌôò (fit + transform ‚Üí DataFrame Î∞òÌôò)
    X_train_processed = pipeline_to_dataframe(pipeline, X_train, fit=True)

    # test Î≥ÄÌôò (transform ‚Üí DataFrame Î∞òÌôò)
    X_test_processed = pipeline_to_dataframe(pipeline, X_test, fit=False)

    print("‚úÖ Train/Test Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å")
    print("Train shape:", X_train_processed.shape)
    print("Test shape :", X_test_processed.shape)
    print("Train columns:", X_train_processed.columns[:20].tolist())

# ----------------------
# Î™®Îç∏ ÌïôÏäµ (RandomForest + SMOTENC)
# ----------------------# ----------------------
# Î™®Îç∏ ÌïôÏäµ (RandomForest + SMOTENC)
# ----------------------
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTENC
import pandas as pd
import numpy as np

# 1) ÌïôÏäµ/Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨
X_tr, X_val, y_tr, y_val = train_test_split(
    X_train_processed, y_train,
    test_size=0.2, random_state=42, stratify=y_train
)

# 2) NaN, inf Ï≤òÎ¶¨ (ÌïôÏäµ/Í≤ÄÏ¶ù Îëò Îã§ ÏïàÏ†ÑÌïòÍ≤å)
X_tr = X_tr.replace([np.inf, -np.inf], -1).fillna(-1)
X_val = X_val.replace([np.inf, -np.inf], -1).fillna(-1)

# 3) Î≤îÏ£ºÌòï Ïª¨Îüº Ïù∏Îç±Ïä§ Ï∞æÍ∏∞
categorical_cols = [c for c in X_train_processed.columns 
                    if c.startswith(("mold_code_", "heating_furnace_", "EMS_operation_time_", "shift_"))]
categorical_features = [X_train_processed.columns.get_loc(c) for c in categorical_cols]

# 4) SMOTENC Ï†ÅÏö© (ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Îßå)
smote_nc = SMOTENC(categorical_features=categorical_features, random_state=42)
X_tr_res, y_tr_res = smote_nc.fit_resample(X_tr, y_tr)

print("Before SMOTE :", y_tr.value_counts().to_dict())
print("After SMOTE  :", pd.Series(y_tr_res).value_counts().to_dict())

# 5) RandomForest Î™®Îç∏ Ï†ïÏùò
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

# 6) ÌïôÏäµ
rf.fit(X_tr_res, y_tr_res)

# 7) Í≤ÄÏ¶ù ÌèâÍ∞Ä
y_pred = rf.predict(X_val)
print("‚úÖ Validation Accuracy:", accuracy_score(y_val, y_pred))
print(classification_report(y_val, y_pred))

# 8) ÏµúÏ¢Ö test ÏòàÏ∏° (SMOTEÎäî testÏóê Ï†ÅÏö© ‚ùå)
X_test_processed = X_test_processed.replace([np.inf, -np.inf], -1).fillna(-1)
test_preds = rf.predict(X_test_processed)

# 9) Í≤∞Í≥º Ï†ÄÏû•
submission = pd.DataFrame({
    "id": test["id"],
    "prediction": test_preds
})
submission.to_csv("submission_rf.csv", index=False)
print("üìÅ submission_rf.csv Ï†ÄÏû• ÏôÑÎ£å")
# ----------------------
# Î™®Îç∏ ÌïôÏäµ (RandomForest + SMOTENC + threshold Ï°∞Ï†ï)
# ----------------------
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTENC
import matplotlib.pyplot as plt

# 1) Train/Validation split
X_tr, X_val, y_tr, y_val = train_test_split(
    X_train_processed, y_train,
    test_size=0.2, random_state=42, stratify=y_train
)

# 2) NaN, inf Ï≤òÎ¶¨
X_tr = X_tr.replace([np.inf, -np.inf], -1).fillna(-1)
X_val = X_val.replace([np.inf, -np.inf], -1).fillna(-1)

# 3) Î≤îÏ£ºÌòï feature Ïù∏Îç±Ïä§
categorical_cols = [c for c in X_train_processed.columns 
                    if c.startswith(("mold_code_", "heating_furnace_", "EMS_operation_time_", "shift_",
                                     "emergency_stop_", "tryshot_signal_"))]
categorical_features = [X_train_processed.columns.get_loc(c) for c in categorical_cols]

# 4) SMOTENC
smote_nc = SMOTENC(categorical_features=categorical_features, random_state=42)
X_tr_res, y_tr_res = smote_nc.fit_resample(X_tr, y_tr)

print("Before SMOTE :", y_tr.value_counts().to_dict())
print("After SMOTE  :", pd.Series(y_tr_res).value_counts().to_dict())

# 5) RandomForest Ï†ïÏùò (Î∂àÎüâ classÏóê Í∞ÄÏ§ëÏπò Í∞ïÌôî ‚Üí Recall ‚Üë)
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1,
    class_weight={0:1, 1:5}   # Î∂àÎüâ(1)Ïóê Í∞ÄÏ§ëÏπò Î∂ÄÏó¨
)

# 6) ÌïôÏäµ
rf.fit(X_tr_res, y_tr_res)

# 7) Validation ÌèâÍ∞Ä (threshold Ï°∞Ï†ï)
y_proba = rf.predict_proba(X_val)[:, 1]

# Í∏∞Î≥∏ threshold=0.5
y_pred_default = (y_proba >= 0.5).astype(int)
print("=== Default threshold (0.5) ===")
print(classification_report(y_val, y_pred_default))

# ÎÇÆÏ∂ò threshold=0.3 ‚Üí Recall ‚Üë
threshold = 0.3
y_pred_custom = (y_proba >= threshold).astype(int)
print(f"=== Custom threshold ({threshold}) ===")
print(classification_report(y_val, y_pred_custom))

# 8) Precision-Recall Curve ÏãúÍ∞ÅÌôî
precisions, recalls, thresholds = precision_recall_curve(y_val, y_proba)
plt.plot(thresholds, precisions[:-1], label="Precision")
plt.plot(thresholds, recalls[:-1], label="Recall")
plt.axvline(x=0.5, color="gray", linestyle="--", label="0.5 threshold")
plt.axvline(x=threshold, color="red", linestyle="--", label=f"{threshold} threshold")
plt.xlabel("Threshold")
plt.ylabel("Score")
plt.legend()
plt.title("Precision-Recall vs Threshold")
plt.show()

# 9) ÏµúÏ¢Ö Test ÏòàÏ∏° (threshold Ï†ÅÏö©)
X_test_processed = X_test_processed.replace([np.inf, -np.inf], -1).fillna(-1)
test_proba = rf.predict_proba(X_test_processed)[:, 1]
test_preds = (test_proba >= threshold).astype(int)

# 10) Ï†ÄÏû•
submission = pd.DataFrame({
    "id": test["id"],
    "prediction": test_preds
})
submission.to_csv("submission_rf.csv", index=False)
print("üìÅ submission_rf.csv Ï†ÄÏû• ÏôÑÎ£å")


X_train



# ÏàòÏπòÌòï Î≥ÄÏàòÎßå Ï∂îÏ∂ú
X_train_numeric = X_train_processed.select_dtypes(include=['int64', 'float64'])

print(X_train_numeric.shape)   # Ìñâ/Ïó¥ ÌÅ¨Í∏∞ ÌôïÏù∏
print(X_train_numeric.columns) # Ïñ¥Îñ§ Ïª¨ÎüºÏù¥ ÎΩëÌòîÎäîÏßÄ ÌôïÏù∏

import pandas as pd
import numpy as np

# ÏàòÏπòÌòï Îç∞Ïù¥ÌÑ∞ÏÖã (X_train_numeric Í∞ÄÏ†ï)
X_train_numeric = X_train.select_dtypes(include=[np.number])

results = {}

for col in X_train_numeric.columns:
    data = X_train_numeric[col].dropna()
    
    # IQR Í≥ÑÏÇ∞
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 3 * IQR
    upper_bound = Q3 + 3 * IQR
    
    # Ï†ïÏÉÅ Î≤îÏúÑ Ïïà Í∞íÎßå ÏÇ¨Ïö©
    filtered = data[(data >= lower_bound) & (data <= upper_bound)]
    mean = filtered.mean()
    std = filtered.std()
    
    # Í∞Å Í∞í œÉ Íµ¨Í∞Ñ ÎùºÎ≤®ÎßÅ
    def sigma_label(x):
        if x < mean - 4*std or x > mean + 4*std:
            return "outlier"
        for i in range(1, 5):
            if mean - i*std <= x <= mean + i*std:
                return f"within {i}œÉ"
        return "beyond 4œÉ"
    
    labels = data.apply(sigma_label)
    
    results[col] = {
        "mean": mean,
        "std": std,
        "lower_bound(IQR*3)": lower_bound,
        "upper_bound(IQR*3)": upper_bound,
        "œÉ Íµ¨Í∞Ñ Î∂ÑÌè¨": labels.value_counts().to_dict()
    }

# ÏöîÏïΩ DataFrame
results_df = pd.DataFrame(results).T
print(results_df.head())   # ÏïûÎ∂ÄÎ∂ÑÎßå ÌôïÏù∏
